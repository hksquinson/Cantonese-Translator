{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/trans/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-03 11:18:10,464 - modelscope - INFO - PyTorch version 2.2.1 Found.\n",
      "2024-04-03 11:18:10,466 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-04-03 11:18:10,507 - modelscope - INFO - Loading done! Current index file version is 1.13.1, with md5 b5a2c5fe01f7460b3e700a8ce7e6fc94 and a total number of 972 components indexed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import bitsandbytes\n",
    "import accelerate\n",
    "from datasets import Dataset\n",
    "\n",
    "from modelscope import snapshot_download\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import PeftModel\n",
    "\n",
    "from custom_tokenizers import YueTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=r'/root/autodl-tmp/01ai/Yi-6B-Chat'\n",
    "model_dir = snapshot_download('01ai/Yi-6B-Chat', cache_dir='/root/autodl-tmp', revision='master')\n",
    "\n",
    "# base_tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True, padding_side='left', max_length=512, return_tensors='pt')\n",
    "\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "# \t model_path,\n",
    "# \t device_map='auto',\n",
    "# \t torch_dtype=torch.bfloat16,\n",
    "# \t trust_remote_code=True \n",
    "# ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate the following words into English:\\n你係邊個？\"},\n",
    "]\n",
    "\n",
    "messages_plain = [\n",
    "    \"\"\"\n",
    "    <|im_start|> user\n",
    "    hi<|im_end|> \n",
    "    <|im_start|> assistant\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# input_ids = base_tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "# output_ids = base_model.generate(input_ids.to('cuda'))\n",
    "# # response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "# response = base_tokenizer.decode(output_ids[0], skip_special_tokens=False, max_length=100)\n",
    "\n",
    "# # Model response: \"Hello! How can I assist you today?\"\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LlamaTokenizer'. \n",
      "The class this function is called from is 'YueTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77969\n"
     ]
    }
   ],
   "source": [
    "tokenizer = YueTokenizer.from_pretrained('/root/autodl-tmp/01ai/Yi-6B-Chat', use_fast=True, padding_side='left', max_length=512, return_tensors='pt')\n",
    "base_tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/01ai/Yi-6B-Chat', use_fast=True, padding_side='left', max_length=512, return_tensors='pt')\n",
    "print(len(tokenizer.vocab))\n",
    "# tokenizer = AutoTokenizer.from_pretrained('/root/AIST4010-Cantonese-Translator/tokenizer', use_fast=True, padding_side='left', max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PeftModel.from_pretrained(\n",
    "#     model,\n",
    "#    '/root/peft_model',\n",
    "#     is_trainable=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.72s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "\t '/root/autodl-tmp/01ai/Yi-6B-Chat',\n",
    "\t device_map=device,\n",
    "\t torch_dtype=torch.bfloat16,\n",
    "     quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    "\t trust_remote_code=True \n",
    ").eval()\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "\t model_path,\n",
    "\t device_map=device,\n",
    "\t torch_dtype=torch.bfloat16,\n",
    "\t quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    "\t trust_remote_code=True \n",
    ").eval()\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.load_adapter('/root/autodl-tmp/peft_model_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DIRECTORY = r'/root/'\n",
    "ABC_DICT_PATH = r'autodl-tmp/AIST4010-Cantonese-Translator-Data/ABC-Dict/abc_dict.csv'\n",
    "\n",
    "def load_abc_dataset():\n",
    "    abc_dict = pd.read_csv(REPO_DIRECTORY + ABC_DICT_PATH)\n",
    "    abc_dataset = Dataset.from_pandas(abc_dict)\n",
    "    return abc_dataset\n",
    "\n",
    "abc_set = load_abc_dataset()\n",
    "abc_shuffled_set = abc_set.train_test_split(seed=42, test_size=0.1)\n",
    "abc_train_set = abc_shuffled_set['train']\n",
    "abc_test_set = abc_shuffled_set['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': 'Translate the following words from Cantonese to English:\\n今日我同學唔小心，踢中我左面粒蛋蛋，好痛啊！'}],\n",
       " [{'role': 'user',\n",
       "   'content': \"Translate the following words from English to Cantonese:\\nToday my classmate wasn't careful, and kicked my left nut. It was very painful!\"}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_translate_prompt(source_language, target_language, source_text):\n",
    "    return f\"Translate the following words from {source_language} to {target_language}:\\n{source_text}\"\n",
    "\n",
    "def get_messages(sample):\n",
    "    def get_translate_prompt(source_language, target_language, source_text):\n",
    "        return f\"Translate the following words from {source_language} to {target_language}:\\n{source_text}\"\n",
    "    return [\n",
    "        [{\"role\": \"user\", \"content\": get_translate_prompt('Cantonese', 'English', sample['yue'])}],\n",
    "        [{\"role\": \"user\", \"content\": get_translate_prompt('English', 'Cantonese', sample['en'])}]\n",
    "    ]\n",
    "\n",
    "train_samples = abc_train_set.shuffle(seed=10).select(range(20))\n",
    "test_samples = abc_test_set.shuffle(seed=10).select(range(20))\n",
    "\n",
    "get_messages(train_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/root/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 10721, 59646, 54274,   534,\n",
      "           453,   453, 13272,   101, 62328, 59642, 59646, 60488, 59724, 61329,\n",
      "         60751, 60751,   101, 59706, 60544, 60530,   103,     7, 59568,   144,\n",
      "             6, 14135,   144, 25585,   826,  1225, 13580, 24870, 19591,   795,\n",
      "           594,   567,  1999,  1682,  1935,    97,   648, 26288,   810,  1272,\n",
      "            99,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Today my classmate accidentally kicked me in the left testicle, it hurts so much!\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144, 25585,   826,  1225, 13580,\n",
      "          3613, 59610, 59570, 11369,    97,   597, 19591,   826,  1999,  6230,\n",
      "            98,   983,   717,  1196, 16465,    99,     7, 59568,   144,     6,\n",
      "         14135,   144, 17957, 54274, 30369, 62328, 38791, 60488, 62295, 59599,\n",
      "         60751,   101,  2418, 60544,   103,     7]], device='cuda:0')\n",
      "Base model:\n",
      "今天的同學不小心踢了我的左邊的蛋，非常痛！\n",
      "\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "def model_output(model, tokenizer, messages, name=None):\n",
    "        for prompt in messages:\n",
    "                input_ids = tokenizer.apply_chat_template(conversation=prompt, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "                with torch.cuda.amp.autocast():\n",
    "                        output_ids = model.generate(input_ids.to('cuda'), max_new_tokens=100)\n",
    "                response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "                # response = tokenizer.decode(output_ids[0], skip_special_tokens=False, max_length=100)\n",
    "                print(output_ids)\n",
    "                print(f\"{name}:\\n{response}\\n\")\n",
    "\n",
    "\n",
    "print([model_output(base_model, base_tokenizer, get_messages(train_samples[0]), 'Base model'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_outputs(samples):\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        prompts = get_messages(sample)\n",
    "        for prompt in prompts:\n",
    "            print(f\"Prompt:\\n{prompt[0]['content']}\")\n",
    "            print()\n",
    "            model_output(base_model, base_tokenizer, [prompt], 'Base model')\n",
    "            model_output(model, tokenizer, [prompt], 'Fine-tuned model')\n",
    "\n",
    "# compare_outputs(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144, 10721, 59646, 54274,\n",
      "           534,   453,   453, 13272,   101, 62328, 59642, 59646, 60488, 59724,\n",
      "         61329, 60751, 60751,   101, 59706, 60544, 60530,   103,     7, 59568,\n",
      "           144,     6, 14135,   144, 25585,   826,  1225, 13580, 24870, 19591,\n",
      "           795,   594,   567,  1999,  1682,  1935,    97,   648, 26288,   810,\n",
      "          1272,    99, 59568, 10721, 59646, 54274,   534,   453,   453, 13272,\n",
      "           101, 62328, 59642, 59646, 60488, 59724, 61329, 60751, 60751,   101,\n",
      "         59706, 60544, 60530,   103, 59568, 10721,   101, 59646, 54274, 30369,\n",
      "         62328, 59642, 38791, 60488, 62295, 60751, 60751,   101, 59706, 60544,\n",
      "         60530,   103, 59568, 10721,   101, 59646, 54274, 30369, 62328, 59642,\n",
      "         38791, 60488, 62295, 60751, 60751,   101, 59706, 60544, 60530,   103,\n",
      "         59568, 10721,   101, 59646, 54274, 30369, 62328, 59642, 38791, 60488,\n",
      "         62295, 60751, 60751,   101, 59706, 60544, 60530,   103, 59568, 10721,\n",
      "           101, 59646, 54274, 30369]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Today my classmate accidentally kicked me in the left testicle, it hurts so much! 今日我同學唔小心，踢中我左面粒蛋蛋，好痛啊！ 今日，我同學不小心踢中了我的左邊蛋蛋，好痛啊！ 今日，我同學不小心踢中了我的左邊蛋蛋，好痛啊！ 今日，我同學不小心踢中了我的左邊蛋蛋，好痛啊！ 今日，我同學不小心\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "          4750,   592, 26212,  2823, 59569, 59601,   144, 25585,   826,  1225,\n",
      "         13580,  3613, 59610, 59570, 11369,    97,   597, 19591,   826,  1999,\n",
      "          6230,    98,   983,   717,  1196, 16465,    99,     7, 59568,   144,\n",
      "             6, 14135,   144, 10721, 59646, 60588, 54274,   534,   453,   453,\n",
      "         13272,   101, 62328, 59665,  2861, 60488,   536,   462,   475,   102,\n",
      "         59706, 60544,   103,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "今日我個同學唔小心，踢到我的左睪。好痛！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_output(model, tokenizer, get_messages(train_samples[0]), 'Fine-tuned model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': \"Today my classmate wasn't careful, and kicked my left nut. It was very painful!\", 'yue': '今日我同學唔小心，踢中我左面粒蛋蛋，好痛啊！'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "今日我同學唔小心，踢中我左面粒蛋蛋，好痛啊！\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 10721, 59646, 54274,   534,\n",
      "           453,   453, 13272,   101, 62328, 59642, 59646, 60488, 59724, 61329,\n",
      "         60751, 60751,   101, 59706, 60544, 60530,   103,     7, 59568,   144,\n",
      "             6, 14135,   144, 25585,   826,  1225, 13580, 24870, 19591,   795,\n",
      "           594,   567,  1999,  1682,  1935,    97,   648, 26288,   810,  1272,\n",
      "            99,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Today my classmate accidentally kicked me in the left testicle, it hurts so much!\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144, 10721, 59646, 54274,\n",
      "           534,   453,   453, 13272,   101, 62328, 59642, 59646, 60488, 59724,\n",
      "         61329, 60751, 60751,   101, 59706, 60544, 60530,   103,     7, 59568,\n",
      "           144,     6, 14135,   144, 25585,   826,  1225, 13580, 24870, 19591,\n",
      "           795,   594,   567,  1999,  7958,    97,   648, 26288,   810,  1272,\n",
      "            99, 59568, 10721, 59646, 54274,   534,   453,   453, 13272,   101,\n",
      "         62328, 59642, 59646, 60488, 59724, 61329, 60751, 60751,   101, 59706,\n",
      "         60544, 60530,   103, 59568, 10721,   101, 59646, 54274, 30369, 62328,\n",
      "         59642, 59646, 60488, 62295,   534,   457,   438, 60751, 60751,   101,\n",
      "         59706, 60544,   534,   455,   453,   103, 59568, 10721,   101, 59646,\n",
      "         54274, 30369, 62328, 59642, 59646, 60488, 62295,   534,   457,   438,\n",
      "         60751, 60751,   101, 59706, 60544, 60530,   103, 59568, 10721,   101,\n",
      "         59646, 54274, 30369, 62328, 59642, 59646, 60488, 62295,   534,   457,\n",
      "           438, 60751, 60751,   101]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Today my classmate accidentally kicked me in the left egg, it hurts so much! 今日我同學唔小心，踢中我左面粒蛋蛋，好痛啊！ 今日，我同學不小心踢中我左邊嘅蛋蛋，好痛喔！ 今日，我同學不小心踢中我左邊嘅蛋蛋，好痛啊！ 今日，我同學不小心踢中我左邊嘅蛋蛋，\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Today my classmate wasn't careful, and kicked my left nut. It was very painful!\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144, 25585,   826,  1225, 13580,\n",
      "          3613, 59610, 59570, 11369,    97,   597, 19591,   826,  1999,  6230,\n",
      "            98,   983,   717,  1196, 16465,    99,     7, 59568,   144,     6,\n",
      "         14135,   144,  3569,  2861, 54274, 12988, 13272,   101, 62328,  2131,\n",
      "          2861, 60488, 62295, 59599, 60751,   102,  2418, 60544,   103,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "今天我的同學不太小心，踢到了我的左邊的蛋。非常痛！\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "          4750,   592, 26212,  2823, 59569, 59601,   144, 25585,   826,  1225,\n",
      "         13580,  3613, 59610, 59570, 11369,    97,   597, 19591,   826,  1999,\n",
      "          6230,    98,   983,   717,  1196, 16465,    99,     7, 59568,   144,\n",
      "             6, 14135,   144, 10721, 59646,   534,   457,   438, 54274,   534,\n",
      "           453,   453, 13272,   101, 62328, 40994,   534,   457,   438, 60488,\n",
      "           536,   462,   495, 62278,   101, 59706, 60544,   103,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "今日我嘅同學唔小心，踢到我嘅左睾丸，好痛！\n",
      "\n",
      "{'en': 'My stomach hurt so I was rolling this way and that on the bed.', 'yue': '我肚痛到捵牀捵蓆。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "我肚痛到捵牀捵蓆。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 59646, 61815, 60544, 59665,\n",
      "           535,   446,   486,   536,   442,   433,   535,   446,   486,   537,\n",
      "           452,   439,   102,     7, 59568,   144,     6, 14135,   144, 59646,\n",
      "         61815, 60544, 59665,   535,   446,   486,   536,   442,   433,   535,\n",
      "           446,   486,   537,   452,   439,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "我肚痛到捵牀捵蓆。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144, 59646, 61815, 60544,\n",
      "         59665,   535,   446,   486,   536,   442,   433,   535,   446,   486,\n",
      "           537,   452,   439,   102,     7, 59568,   144,     6, 14135,   144,\n",
      "         59646, 61815, 60544, 59665,   535,   446,   486,   536,   442,   433,\n",
      "           535,   446,   486,   537,   452,   439,   102,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "我肚痛到捵牀捵蓆。\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "My stomach hurt so I was rolling this way and that on the bed.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144,  6056, 15112,  8192,   810,\n",
      "           616,   717, 14967,   719,  1217,   597,   639,   632,   567,  3807,\n",
      "            98,     7, 59568,   144,     6, 14135,   144,  2861, 61186, 60544,\n",
      "         16729,   534,   447,   483, 60323,   101, 25907,   535,   492,   495,\n",
      "         60599,   535,   492,   495, 59793, 59696, 26682, 22085,   102,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "我的胃痛得很厲害，所以我滾來滾去地躺在床上。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "          4750,   592, 26212,  2823, 59569, 59601,   144,  6056, 15112,  8192,\n",
      "           810,   616,   717, 14967,   719,  1217,   597,   639,   632,   567,\n",
      "          3807,    98,     7, 59568,   144,     6, 14135,   144, 59646, 61815,\n",
      "         60544,   534,   451,   456,   101,  1953,  8081,   535,   446,   483,\n",
      "           534,   451,   456,   535,   446,   483,   534,   455,   491, 60741,\n",
      "         59781,   102,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "我肚痛咗，所以我就捲咗捲喺床度。\n",
      "\n",
      "{'en': \"I'm sorry, I can't recall right off the bat where those things of yours had got placed.\", 'yue': '唔好意思，我一時醒唔起你嗰啲嘢放咗喺邊度嘅。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "唔好意思，我一時醒唔起你嗰啲嘢放咗喺邊度嘅。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144,   534,   453,   453, 59706,\n",
      "          7112,   101, 33442, 60531, 60808,   534,   453,   453, 59786, 59725,\n",
      "           534,   456,   481,   534,   454,   483,   534,   457,   467, 59932,\n",
      "           534,   451,   456,   534,   455,   491, 62295, 59781,   534,   457,\n",
      "           438,   102,     7, 59568,   144,     6, 14135,   144, 31368,   101,\n",
      "         59646, 22037,  1327, 16291, 59725, 59937,  4898,  4298,  7752,  9383,\n",
      "         59633,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "对不起，我一时没有想起你把那些东西放在哪里了。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144,   534,   453,   453,\n",
      "         59706,  7112,   101, 33442, 60531, 60808,   534,   453,   453, 59786,\n",
      "         59725,   534,   456,   481,   534,   454,   483,   534,   457,   467,\n",
      "         59932,   534,   451,   456,   534,   455,   491, 62295, 59781,   534,\n",
      "           457,   438,   102,     7, 59568,   144,     6, 14135,   144, 36778,\n",
      "            97,   616,  2040, 59610, 59570,  5386,   788,  3695,   717,  1710,\n",
      "          8614,    98, 59568,   534,   453,   453, 59706,  7112,   101, 59646,\n",
      "           534,   453,   453, 59861, 59725,   534,   454,   483,   534,   457,\n",
      "           467, 59932,   534,   451,   456,   534,   455,   491, 62295, 59781,\n",
      "           534,   457,   438,   102, 59568,   534,   453,   453, 59706,  7112,\n",
      "           101, 59646,   534,   453,   453, 59861, 59725,   534,   454,   483,\n",
      "           534,   457,   467, 59932,   534,   451,   456,   534,   455,   491,\n",
      "         62295, 59781,   534,   457,   438,   102, 59568,   534,   453,   453,\n",
      "         59706,  7112,   101, 59646,   534,   453,   453, 59861, 59725,   534,\n",
      "           454,   483,   534,   457,   467, 59932,   534,   451,   456]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Sorry, I didn't notice your stuff was put somewhere. 唔好意思，我唔知你啲嘢放咗喺邊度嘅。 唔好意思，我唔知你啲嘢放咗喺邊度嘅。 唔好意思，我唔知你啲嘢放咗\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "I'm sorry, I can't recall right off the bat where those things of yours had got placed.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144, 59597, 59610, 59583,  9509,\n",
      "            97,   616,   748, 59610, 59570,  8249,  1288,   965,   567, 10880,\n",
      "          1151,  1367,  1613,   593, 12796,   986,  1656,  6594,    98,     7,\n",
      "         59568,   144,     6, 14135,   144, 59646,   534,   453,   453, 59861,\n",
      "           101, 59646,   534,   453,   453, 61641, 59721, 59625, 63598, 59701,\n",
      "         59742, 59725,   534,   457,   438,   534,   457,   467, 59932,   534,\n",
      "           455,   491, 62295,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "我唔知，我唔記得一陣子前你嘅嘢放喺邊。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "          4750,   592, 26212,  2823, 59569, 59601,   144, 59597, 59610, 59583,\n",
      "          9509,    97,   616,   748, 59610, 59570,  8249,  1288,   965,   567,\n",
      "         10880,  1151,  1367,  1613,   593, 12796,   986,  1656, 76133,  1203,\n",
      "            98,     7, 59568,   144,     6, 14135,   144, 68422, 59568,   534,\n",
      "           453,   453, 59706,  7112,    97, 24840,   534,   453,   453, 61641,\n",
      "         59721, 59725,   534,   457,   438,   534,   457,   467,   534,   455,\n",
      "           491, 62295, 59781,   102,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "唔好意思, 我唔記得你嘅嘢喺邊度。\n",
      "\n",
      "{'en': 'According to what the old folks say, the winter solstice is more important than the Chinese New Year.', 'yue': '啲老人家話事偈，冬大過年。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "啲老人家話事偈，冬大過年。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144,   534,   454,   483, 50873,\n",
      "         61845, 59736,   534,   434,   441,   101, 60820, 59647, 60799, 59663,\n",
      "           102,     7, 59568,   144,     6, 14135,   144,  1263,  1926,  3151,\n",
      "           742, 26212,  2823, 59569, 19293,   592,  4750,   659,  3964, 59601,\n",
      "           144,   144, 50873,   839, 42222,   627,  1514,   144, 61845, 59736,\n",
      "           534,   434,   441,   839, 19474,   881,  4569,   144, 60820, 59647,\n",
      "         60799, 59663,   839,   983, 59610, 59575, 52348,   989,  7284,  1773,\n",
      "           567,  7814,  2799,    98,     7]], device='cuda:0')\n",
      "Base model:\n",
      "The following words from Cantonese translate to English as follows:\n",
      "\n",
      "老人家 - Elderly person\n",
      "話事偈 - Say their piece\n",
      "冬大過年 - It's colder than usual during the winter months.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144,   534,   454,   483,\n",
      "         50873, 61845, 59736,   534,   434,   441,   101, 60820, 59647, 60799,\n",
      "         59663,   102,     7, 59568,   144,     6, 14135,   144,  1263, 49066,\n",
      "          1441,   648, 59610, 59575, 72366,  3662,   593,  7814,   639,   678,\n",
      "          7577,   989,   567,   990,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "The elders say it'srs of winter that are bigger than the year.\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "According to what the old folks say, the winter solstice is more important than the Chinese New Year.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144, 39559,   592,   981,   567,\n",
      "          1851,  8413,  1441,    97,   567,  7814,  1496,   608,   830,   620,\n",
      "           863,  1941,   989,   567,  6837,  1876,  8567,    98,     7, 59568,\n",
      "           144,     6, 14135,   144, 39559,   592,   981,   567,  1851,  8413,\n",
      "          1441,    97,   567,  7814,  1496,   608,   830,   620,   863,  1941,\n",
      "           989,   567,  6837,  1876,  8567,    98,     7]], device='cuda:0')\n",
      "Base model:\n",
      "According to what the old folks say, the winter solstice is more important than the Chinese New Year.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "          4750,   592, 26212,  2823, 59569, 59601,   144, 39559,   592,   981,\n",
      "           567,  1851,  8413,  1441,    97,   567,  7814,  1496,   608,   830,\n",
      "           620,   863,  1941,   989,   567,  6837,  1876,  8567,    98,     7,\n",
      "         59568,   144,     6, 14135,   144, 29630, 50873, 62364,   101, 52776,\n",
      "         59806, 27480, 61669,  2377,   102,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "根據老人家講，冬至比新年仲重要。\n",
      "\n",
      "{'en': \"Tonight we've been invited to a wedding banquet.\", 'yue': '今晚有人請飲。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "今晚有人請飲。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 33490,  5189, 61919, 63105,\n",
      "           102,     7, 59568,   144,     6, 14135,   144, 59592, 33490,  5189,\n",
      "         61919, 63105, 59592, 59568,  1229, 15480, 59648,  1529,  6444,   620,\n",
      "          2491,   896,   620, 28516,   631, 14519, 10469,    98, 59592,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "\"今晚有人請飲\" 可以翻译为 \"There is someone who is inviting for drinks tonight.\"\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144, 33490,  5189, 61919,\n",
      "         63105,   102,     7, 59568,   144,     6, 14135,   144, 39530,    97,\n",
      "          2491, 12456,   745,   592,  4561,    98, 59568,   144, 33490,  5189,\n",
      "         61919, 63105,   102,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Tonight, someone invited us to drink. \n",
      "今晚有人請飲。\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Tonight we've been invited to a wedding banquet.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144, 59600, 51152,   666, 59610,\n",
      "           613,   961, 12456,   592,   562,  8760,  7255,  3134,    98,     7,\n",
      "         59568,   144,     6, 14135,   144, 33490,  8506, 59777, 54280, 31985,\n",
      "         60424, 62101,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "今晚我們被邀請參加婚宴。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "          4750,   592, 26212,  2823, 59569, 59601,   144, 59600, 51152,   666,\n",
      "         59610,   613,   961, 12456,   592,   562,  8760,  7255,  3134,    98,\n",
      "             7, 59568,   144,     6, 14135,   144, 33490,  8506, 59777, 54280,\n",
      "         59793, 60424, 62101,   102,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "今晚我們被邀請去婚宴。\n",
      "\n",
      "{'en': 'He has not yet been to school, or He has not studied for it yet.', 'yue': '佢未讀書。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "佢未讀書。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144,   533,   494,   467, 60049,\n",
      "         62283, 61473,   102,     7, 59568,   144,     6, 14135,   144, 59592,\n",
      "           533,   494,   467, 60049, 62283, 61473,   102, 59592, 59568,  7112,\n",
      "         12355,  1529, 59686, 59598, 59887, 61146, 61212, 62283, 61473,   102,\n",
      "         59592, 59568, 60565, 60493, 61845, 23072, 59632, 12029, 60080, 59634,\n",
      "         61146, 10870,  3301, 60080, 61906, 20911, 58606,  2850, 61146, 10870,\n",
      "         29885, 60080, 60588, 59767,   535,   439,   450,   102,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "\"佢未讀書。\" 意思是指 \"他/她還沒讀書。\" 這句話可以用在描述某人還沒有完成某項學習任務或者還沒有獲得某個文憑。\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926, 71864,  1994,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144,   533,   494,   467,\n",
      "         60049, 62283, 61473,   102,     7, 59568,   144,     6, 14135,   144,\n",
      "          4431,  8934, 59610, 59570,  1326,   567,  1687,    98, 59568, 59686,\n",
      "         60049, 62283, 61473,   102, 59568,   533,   494,   467, 60049, 62283,\n",
      "         61473,   102, 59568,   533,   494,   467, 60049, 62283, 61473,   102,\n",
      "         59568,   533,   494,   467, 60049, 62283, 61473,   102, 59568,   533,\n",
      "           494,   467, 60049, 62283, 61473,   102, 59568,   533,   494,   467,\n",
      "         60049, 62283, 61473,   102, 59568,   533,   494,   467, 60049, 62283,\n",
      "         61473,   102, 59568,   533,   494,   467, 60049, 62283, 61473,   102,\n",
      "         59568,   533,   494,   467, 60049, 62283, 61473,   102, 59568,   533,\n",
      "           494,   467, 60049, 62283, 61473,   102, 59568,   533,   494,   467,\n",
      "         60049, 62283, 61473,   102, 59568,   533,   494,   467, 60049, 62283]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "He hasn't read the book. 他未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀書。 佢未讀\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "He has not yet been to school, or He has not studied for it yet.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompare_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mcompare_outputs\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBase model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model_output(model, tokenizer, [prompt], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tuned model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36mmodel_output\u001b[0;34m(model, tokenizer, messages, name)\u001b[0m\n\u001b[1;32m      3\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(conversation\u001b[38;5;241m=\u001b[39mprompt, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m----> 5\u001b[0m         output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m response \u001b[38;5;241m=\u001b[39m base_tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m][input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# response = tokenizer.decode(output_ids[0], skip_special_tokens=False, max_length=100)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/generation/utils.py:1592\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1585\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1586\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1587\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1589\u001b[0m     )\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1610\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1611\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1616\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1617\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/generation/utils.py:2696\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2695\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2696\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2697\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2704\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1176\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1173\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1176\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1019\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1009\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1010\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         cache_position,\n\u001b[1;32m   1017\u001b[0m     )\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1019\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:755\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    754\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 755\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    758\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:241\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    239\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:687\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 687\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mhas_fp16_weights:\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCxB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;66;03m# we converted 8-bit row major to turing/ampere format in the first inference pass\u001b[39;00m\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;66;03m# we no longer need the row-major weight\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:562\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    561\u001b[0m     state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul8bitLt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:401\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_igemmlt:\n\u001b[1;32m    400\u001b[0m     C32A, SA \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mtransform(CA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 401\u001b[0m     out32, Sout32 \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43migemmlt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC32A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCxB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m bias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# we apply the fused bias here\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmm_dequant(out32, Sout32, SCA, state\u001b[38;5;241m.\u001b[39mSCB, bias\u001b[38;5;241m=\u001b[39mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/functional.py:1895\u001b[0m, in \u001b[0;36migemmlt\u001b[0;34m(A, B, SA, SB, out, Sout, dtype)\u001b[0m\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mtuple\u001b[39m(shapeA[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m [shapeB[\u001b[38;5;241m0\u001b[39m]]), device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dimsA \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1895\u001b[0m     out, Sout \u001b[38;5;241m=\u001b[39m \u001b[43mget_transform_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapeA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapeB\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcol32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dimsA \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1899\u001b[0m     out, Sout \u001b[38;5;241m=\u001b[39m get_transform_buffer(\n\u001b[1;32m   1900\u001b[0m         (shapeA[\u001b[38;5;241m0\u001b[39m], shapeA[\u001b[38;5;241m1\u001b[39m], shapeB[\u001b[38;5;241m0\u001b[39m]), dtype, A\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1901\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/functional.py:482\u001b[0m, in \u001b[0;36mget_transform_buffer\u001b[0;34m(shape, dtype, device, to_order, from_order, transpose)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# blocks of 32 columns (padded)\u001b[39;00m\n\u001b[1;32m    481\u001b[0m     cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m ((cols \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m31\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, state\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_turing\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;66;03m# blocks of 32 columns and 8 rows\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m ((cols \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m31\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_outputs(train_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'Miss Linda.', 'yue': 'Linda姐。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "Linda姐。\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model:\n",
      "Linda姐.\n",
      "\n",
      "SFT model:\n",
      "Linda, or Miss Linda. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Miss Linda.\n",
      "\n",
      "Base model:\n",
      "Miss Linda.\n",
      "\n",
      "SFT model:\n",
      "李生。 \n",
      "\n",
      "{'en': 'What is he doing in the kitchen to make such banging and clanging noise?', 'yue': '佢喺廚房度打得咁𠽤叻𡃈嘞做乜嘢啊？'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "佢喺廚房度打得咁𠽤叻𡃈嘞做乜嘢啊？\n",
      "\n",
      "Base model:\n",
      "\"佢喺廚房度打得咁𠽤叻𡃈嘞做乜嘢啊？\" 可以翻译为 \"他在厨房里打得这么好啊？\" 或者 \"他在厨房里打得这么好吗？\" 其中，\"打得咁𠽤叻𡃈嘞\" 表示打得很厉害，\"做乜嘢啊？\" 表示在做些什么。\n",
      "\n",
      "SFT model:\n",
      "What is he doing in the kitchen looking so engrossed in his work? \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "What is he doing in the kitchen to make such banging and clanging noise?\n",
      "\n",
      "Base model:\n",
      "他在廚房裡做什麼會發出這麼大的敲擊和碰撞噪音？\n",
      "\n",
      "SFT model:\n",
      "佢喺廚房咁多嘈? \n",
      "\n",
      "{'en': 'How high do you think the possibility of success for this matter will be?', 'yue': '計你話呢件事嘅成數會有幾高呢？'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "計你話呢件事嘅成數會有幾高呢？\n",
      "\n",
      "Base model:\n",
      "Translation from Cantonese to English:\n",
      "\"How high do you think the number for this matter will be?\"\n",
      "\n",
      "SFT model:\n",
      "How high do you think the chances of this matter turning out well are? \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "How high do you think the possibility of success for this matter will be?\n",
      "\n",
      "Base model:\n",
      "在這件事上你認為成功的可能性有多大？\n",
      "\n",
      "SFT model:\n",
      "你估呢單嘢成功機會有幾高啊？ \n",
      "\n",
      "{'en': 'Nowadays very few people wear Chinese-style jackets and trousers.', 'yue': '今時今日好少人着唐裝衫嘞。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "今時今日好少人着唐裝衫嘞。\n",
      "\n",
      "Base model:\n",
      "\"今時今日好少人着唐裝衫嘞。\" \n",
      "\n",
      "Translation: \"Nowadays, it is rare to see people wearing traditional Chinese clothing (唐裝).\"\n",
      "\n",
      "SFT model:\n",
      "Nowadays very few people wear traditional Chinese dress. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Nowadays very few people wear Chinese-style jackets and trousers.\n",
      "\n",
      "Base model:\n",
      "現今很少人穿中式外套和褲子。\n",
      "\n",
      "SFT model:\n",
      "而家好少人着唐裝西裝。 \n",
      "\n",
      "{'en': 'The kid is so naughty he deserves a spanking!', 'yue': '個細蚊仔咁曳，真抵打！'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "個細蚊仔咁曳，真抵打！\n",
      "\n",
      "Base model:\n",
      "\"個細蚊仔咁曳，真抵打！\" 可以翻译为 \"That little mosquito is so annoying, it really deserves a beating!\" 其中，\"個細蚊仔\" 指的是 \"那個小蚊子\"，\"咁曳\" 指的是 \"so annoying\"，\"真抵打\" 指的是 \"it really deserves a beating\"。\n",
      "\n",
      "SFT model:\n",
      "The young boy is so naughty, he really deserves to be beaten! \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "The kid is so naughty he deserves a spanking!\n",
      "\n",
      "Base model:\n",
      "The kid is so naughty he deserves a spanking!\n",
      "\n",
      "SFT model:\n",
      "個細蚊仔咁叻，！ \n",
      "\n",
      "{'en': 'After he retired he then lived a hard life supported by his meager savings.', 'yue': '佢退休之後就要捱穀種。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "佢退休之後就要捱穀種。\n",
      "\n",
      "Base model:\n",
      "After he retires, he has to endure the hardships of farming.\n",
      "\n",
      "SFT model:\n",
      "After he retires he will have to live on his savings. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "After he retired he then lived a hard life supported by his meager savings.\n",
      "\n",
      "Base model:\n",
      "在他退休後，他過上了拮据的生活，依靠微薄的儲蓄來維持。\n",
      "\n",
      "SFT model:\n",
      "佢咗之後就捱。 \n",
      "\n",
      "{'en': 'I have only one mouth, so how can I eat so much?', 'yue': '我一個人得一把口，唔食得咁多？'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "我一個人得一把口，唔食得咁多？\n",
      "\n",
      "Base model:\n",
      "\"我一個人得一把口，唔食得咁多？\" 可以翻译为 \"我一个人吃得不多，是不是？\" 或者 \"我一个人吃得不多，对吗？\" 这里的 \"一把口\" 是指 \"一个人\"，\"唔食得咁多\" 是指 \"吃不太多\"。\n",
      "\n",
      "SFT model:\n",
      "I'm alone with only one mouth, so how can I eat so much? \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "I have only one mouth, so how can I eat so much?\n",
      "\n",
      "Base model:\n",
      "我只有一個嘴，所以怎麼可能吃得那麼多？\n",
      "\n",
      "SFT model:\n",
      "我一個嘴，點食得咁多嘢啊？ \n",
      "\n",
      "{'en': \"Lots of times when taking Light Rail I see people get off the train and not swipe their Octopus cards on the machine, so it's quite obvious that before they had boarded the train they hadn't used their Octopus cards.\", 'yue': '我搭輕鐵好多時見到有人落車唔嘟機，好明顯佢哋上車前都冇嘟機。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "我搭輕鐵好多時見到有人落車唔嘟機，好明顯佢哋上車前都冇嘟機。\n",
      "\n",
      "Base model:\n",
      "我搭輕鐵好多時見到有人落車唔嘟機，好明顯佢哋上車前都冇嘟機。\n",
      "\n",
      "SFT model:\n",
      "When I take the light rail quite often I see people get on the train without tapping their Octopus cards. It's obvious they didn't tap their cards when they boarded the train. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Lots of times when taking Light Rail I see people get off the train and not swipe their Octopus cards on the machine, so it's quite obvious that before they had boarded the train they hadn't used their Octopus cards.\n",
      "\n",
      "Base model:\n",
      "在乘搭輕鐵的很多次經驗中，我見到有人下車時沒有在機器上刷八達通卡，所以很明顯地，在他們上車前並沒有使用八達通卡。\n",
      "\n",
      "SFT model:\n",
      "我搭輕鐵時好多次見到有人落車冇咭機，好明顯佢哋車前唔用咭。 \n",
      "\n",
      "{'en': 'What I have sold to you are all genuine items.', 'yue': '我賣畀你嘅全部係堅嘢。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "我賣畀你嘅全部係堅嘢。\n",
      "\n",
      "Base model:\n",
      "\"我賣畀你嘅全部係堅嘢。\" \n",
      "\n",
      "Translation from Cantonese to English:\n",
      "\"What I sell to you is all solid.\"\n",
      "\n",
      "SFT model:\n",
      "All the stuff I've sold you are all genuine goods. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "What I have sold to you are all genuine items.\n",
      "\n",
      "Base model:\n",
      "在賣給你的所有物品都是真品。\n",
      "\n",
      "SFT model:\n",
      "我賣畀你嘅都係正貨。 \n",
      "\n",
      "{'en': 'Where shall we go today to hang out?', 'yue': '我哋今日去邊度蒲啊？'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "我哋今日去邊度蒲啊？\n",
      "\n",
      "Base model:\n",
      "\"我哋今日去邊度蒲啊？\" 可以翻译为 \"我们今天要去哪里玩呢？\" 或者 \"我们今天要去哪里聚会呢？\" 这里的 \"蒲\" 是一个粤语词汇，意思是 \"聚会、玩乐\"。\n",
      "\n",
      "SFT model:\n",
      "Where are we going to hang out today? \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Where shall we go today to hang out?\n",
      "\n",
      "Base model:\n",
      "今天我们去哪里闲逛？\n",
      "\n",
      "SFT model:\n",
      "今日去邊度蒲？ \n",
      "\n",
      "{'en': 'Many teenaged girls try to act like adults and start smoking when they are young.', 'yue': '好多𡃁妹仔細細個就學人食煙。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "好多𡃁妹仔細細個就學人食煙。\n",
      "\n",
      "Base model:\n",
      "Many young girls started smoking very young.\n",
      "\n",
      "SFT model:\n",
      "Many young girls very young have learned from others to smoke cigarettes. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Many teenaged girls try to act like adults and start smoking when they are young.\n",
      "\n",
      "Base model:\n",
      "在年輕時，許多青少年女孩試圖表現得像成年人，並且開始吸煙。\n",
      "\n",
      "SFT model:\n",
      "好多女仔都好想扮大，細個嗰陣時就開始食煙。 \n",
      "\n",
      "{'en': 'After getting off work and returning home, I then change into casual clothes and go buy food to prepare.', 'yue': '落咗班返屋企就着住街坊裝去買餸。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "落咗班返屋企就着住街坊裝去買餸。\n",
      "\n",
      "Base model:\n",
      "\"落咗班\" means \"finished work\" or \"left work.\"\n",
      "\n",
      "\"返屋企\" means \"go back home.\"\n",
      "\n",
      "\"就着住\" means \"stay by.\"\n",
      "\n",
      "\"街坊\" means \"neighbors.\"\n",
      "\n",
      "\"裝\" is a verb in Cantonese that means \"to go.\"\n",
      "\n",
      "\"去買餸\" means \"go to buy groceries.\"\n",
      "\n",
      "SFT model:\n",
      "After I got off work I went home and changed into my street clothes before going out to buy food. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "After getting off work and returning home, I then change into casual clothes and go buy food to prepare.\n",
      "\n",
      "Base model:\n",
      "在下班後回到家，我會換上便服，然後去買食物準備。\n",
      "\n",
      "SFT model:\n",
      "放工返屋企，我就換咗件嘅衫出街，買咗啲嘅嘢做咗嘢先至返屋企。 \n",
      "\n",
      "{'en': \"The hill has no trees or grass, so it's devoid of any covering.\", 'yue': '個山冇樹又冇草，光脫脫噉。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "個山冇樹又冇草，光脫脫噉。\n",
      "\n",
      "Base model:\n",
      "The following words from Cantonese are being translated to English:\n",
      "\n",
      "個 - 一个\n",
      "山 - 山\n",
      "冇 - 没有\n",
      "樹 - 树\n",
      "又 - 又\n",
      "冇 - 没有\n",
      "草 - 草\n",
      "光 - 光\n",
      "脫 - 脱\n",
      "脫脫 - 光光\n",
      "噉 - 这样\n",
      "\n",
      "Translation: There is no mountain, no trees, and no grass. It is just a plain.\n",
      "\n",
      "SFT model:\n",
      "There's no tree or grass on the hill, so it's bare and dry. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "The hill has no trees or grass, so it's devoid of any covering.\n",
      "\n",
      "Base model:\n",
      "The hill is 無樹木亦無草，所以它是 無遮蓋的。\n",
      "\n",
      "SFT model:\n",
      "山樹樹，冇乜遮蔽。 \n",
      "\n",
      "{'en': 'The young boy sits on the tree stump.', 'yue': '個細路仔坐响樹頭上便。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "個細路仔坐响樹頭上便。\n",
      "\n",
      "Base model:\n",
      "The following words from Cantonese are being translated to English:\n",
      "\n",
      "個 - \"ko\" (literally means \"one\" or \"a\")\n",
      "細路仔 - \"siu2 lam4 zi2\" (literally means \"small road child\", but in this context, it refers to a young child)\n",
      "坐 - \"zo2\" (means to sit)\n",
      "響 - \"heon2\" (means to sound or to be heard)\n",
      "樹頭上 - \"sui4 tou2 saang1\" (literally means \"tree top\", but in this context, it refers to the branch or the top of the tree)\n",
      "便 - \"bin2\" (means to go or to do something immediately after)\n",
      "\n",
      "SFT model:\n",
      "The young boy is sitting on the tree. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "The young boy sits on the tree stump.\n",
      "\n",
      "Base model:\n",
      "在樹墩上，年輕男孩坐著。\n",
      "\n",
      "SFT model:\n",
      "個細路仔坐喺個樹樘上。 \n",
      "\n",
      "{'en': \"If some English words seep into your Cantonese, it's quite normal that you then pronounce them incorrectly. It's because you're not really speaking English, you've only mixed some English words into your Cantonese\", 'yue': '如果你嘅粵語入邊滲咗啲英文詞彙，就讀歪音係好正常嘅，因為你唔係真係講緊英文，靜係將啲英文字融入粵語喎！'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "如果你嘅粵語入邊滲咗啲英文詞彙，就讀歪音係好正常嘅，因為你唔係真係講緊英文，靜係將啲英文字融入粵語喎！\n",
      "\n",
      "Base model:\n",
      "If you've incorporated some English words into your Cantonese, it's perfectly normal, as you're not really speaking English; you're just infusing English words into Cantonese!\n",
      "\n",
      "SFT model:\n",
      "If you have some English words in your Cantonese speech, it's quite normal, as you're not really speaking English. You're just mixing English words into Cantonese. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "If some English words seep into your Cantonese, it's quite normal that you then pronounce them incorrectly. It's because you're not really speaking English, you've only mixed some English words into your Cantonese\n",
      "\n",
      "Base model:\n",
      "如果一些英语词汇渗入你的广东话，那么你偶尔发音错误是很正常的，因为你并不是在说英语，你只是在你的广东话中混合了一些英语词汇。\n",
      "\n",
      "SFT model:\n",
      "如果你啲英文入嚟，好正常，因為你唔係講，係夾嚟講。 \n",
      "\n",
      "{'en': 'We now want to take our sons and daughters out to eat half-priced buffet.', 'yue': '依家我哋要帶啲囝囝囡囡出街食半價布菲。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "依家我哋要帶啲囝囝囡囡出街食半價布菲。\n",
      "\n",
      "Base model:\n",
      "Currently, we need to take our children out to enjoy half-priced brunch.\n",
      "\n",
      "SFT model:\n",
      "Now we need to take our children out to eat a half-price buffet. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "We now want to take our sons and daughters out to eat half-priced buffet.\n",
      "\n",
      "Base model:\n",
      "在我們現在想帶我們的兒女去吃半價自助餐。\n",
      "\n",
      "SFT model:\n",
      "我哋而家想帶埋細路仔女去食半。 \n",
      "\n",
      "{'en': \"You're making that kind of decision, so people may request that you give an explanation for it.\", 'yue': '你做噉樣嘅決定，人哋會要求你解畫嘅噃。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "你做噉樣嘅決定，人哋會要求你解畫嘅噃。\n",
      "\n",
      "Base model:\n",
      "You make such a decision, people will ask you to explain it, right?\n",
      "\n",
      "SFT model:\n",
      "If you make such a decision, people will demand that you explain yourself. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "You're making that kind of decision, so people may request that you give an explanation for it.\n",
      "\n",
      "Base model:\n",
      "在做出那種決定時，別人可能會要求你為此提供解釋。\n",
      "\n",
      "SFT model:\n",
      "你做嗰啲嘢，好可能會有人要求你解釋嘅。 \n",
      "\n",
      "{'en': \"The size of a blue whale's heart is almost as big as a car.\", 'yue': '藍鯨嘅心臟大細同車差唔多咁大。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "藍鯨嘅心臟大細同車差唔多咁大。\n",
      "\n",
      "Base model:\n",
      "The heart of the blue whale is as large as a car.\n",
      "\n",
      "SFT model:\n",
      "The blue whale's heart is about the same size as the car. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "The size of a blue whale's heart is almost as big as a car.\n",
      "\n",
      "Base model:\n",
      "在藍鯨的心臟大得幾乎就像一輛車一樣。\n",
      "\n",
      "SFT model:\n",
      "藍嘅心臟嘅大小近似車咁大。 \n",
      "\n",
      "{'en': 'In former times some people would become very angry as soon as they heard someone say he was selling insurance, as they felt like they were being cursed to die.', 'yue': '以前啲人一聽話賣燕梳就會好嬲，覺得好似咒緊佢哋去死噉。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "以前啲人一聽話賣燕梳就會好嬲，覺得好似咒緊佢哋去死噉。\n",
      "\n",
      "Base model:\n",
      "以前有些人一聽說賣燕窩就會很生氣，覺得好像在詛咒他們去死一樣。\n",
      "\n",
      "SFT model:\n",
      "In the past when people heard someone say sell the they would be quite angry. They seemed to be cursing them to die. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "In former times some people would become very angry as soon as they heard someone say he was selling insurance, as they felt like they were being cursed to die.\n",
      "\n",
      "Base model:\n",
      "在昔日的時候，有些人會對聽到有人說他在賣保險就變得很生氣，因為他們覺得自己好像被詛咒要死了一樣。\n",
      "\n",
      "SFT model:\n",
      "以前有啲人一聽到有人賣保險就發爛渣，好似俾人詛咒死噉。 \n",
      "\n",
      "{'en': 'Last night thirty people came to attend my class.', 'yue': '琴晚有卅個人嚟上我嘅堂。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "琴晚有卅個人嚟上我嘅堂。\n",
      "\n",
      "Base model:\n",
      "Translation: There were thirty people came to my class in the evening.\n",
      "\n",
      "SFT model:\n",
      "Last night thirty people came to take my class. \n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Last night thirty people came to attend my class.\n",
      "\n",
      "Base model:\n",
      "昨晚三十個人來參加我的班級。\n",
      "\n",
      "SFT model:\n",
      "琴晚有三十三個人嚟上我堂。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_outputs(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_translate_prompt() missing 1 required positional argument: 'source_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m train_sample \u001b[38;5;241m=\u001b[39m abc_train_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      7\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m abc_test_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m en_train_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCantonese\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     10\u001b[0m en_test_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCantonese\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m test_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     11\u001b[0m yue_train_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myue\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m train_sample \u001b[38;5;241m=\u001b[39m abc_train_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      7\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m abc_test_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m en_train_messages \u001b[38;5;241m=\u001b[39m {\u001b[43mget_translate_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCantonese\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     10\u001b[0m en_test_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCantonese\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m test_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     11\u001b[0m yue_train_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myue\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "\u001b[0;31mTypeError\u001b[0m: get_translate_prompt() missing 1 required positional argument: 'source_text'"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate the following words into English:\\n乜嘢都係波士決定嘅，打工仔啲人淨係得個知字。\\n\"},\n",
    "]\n",
    "\n",
    "# get 5 random samples from train and test dataset\n",
    "train_sample = abc_train_set.shuffle(seed=42).select(range(5))\n",
    "test_sample = abc_test_set.shuffle(seed=42).select(range(5))\n",
    "\n",
    "en_train_messages = {get_translate_prompt('Cantonese', sentence) for sentence in train_sample['en']}\n",
    "en_test_messages = {get_translate_prompt('Cantonese', sentence) for sentence in test_sample['en']}\n",
    "yue_train_messages = {get_translate_prompt('English', sentence) for sentence in train_sample['yue']}\n",
    "yue_test_messages = {get_translate_prompt('English', sentence) for sentence in test_sample['yue']}\n",
    "\n",
    "for messages in [en_train_messages, en_test_messages, yue_train_messages, yue_test_messages]:\n",
    "    for message in messages:\n",
    "        print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedError",
     "evalue": "'str object' has no attribute 'role'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_generation_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1745\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[0;34m(self, conversation, chat_template, add_generation_prompt, tokenize, padding, truncation, max_length, return_tensors, return_dict, **tokenizer_kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# Compilation function uses a cache to avoid recompiling the same template\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m compiled_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_jinja_template(chat_template)\n\u001b[0;32m-> 1745\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_generation_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_generation_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial_tokens_map\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# There's only one sequence here, so \"longest\" makes no sense\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/jinja2/environment.py:1301\u001b[0m, in \u001b[0;36mTemplate.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_render_func(ctx))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/jinja2/environment.py:936\u001b[0m, in \u001b[0;36mEnvironment.handle_exception\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Exception handling helper.  This is used internally to either raise\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03mrewritten exceptions or return a rendered traceback for the template.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rewrite_traceback_stack\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m rewrite_traceback_stack(source\u001b[38;5;241m=\u001b[39msource)\n",
      "File \u001b[0;32m<template>:2\u001b[0m, in \u001b[0;36mtop-level template code\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUndefinedError\u001b[0m: 'str object' has no attribute 'role'"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "output_ids = model.generate(input_ids.to('cuda'))\n",
    "# response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "\n",
    "# Model response: \"Hello! How can I assist you today?\"\n",
    "print(\"Tuned model:\", response)\n",
    "\n",
    "input_ids = base_tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "output_ids = base_model.generate(input_ids.to('cuda'))\n",
    "# response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "\n",
    "print(\"Base model:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
