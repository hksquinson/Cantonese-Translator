{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/trans/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-05 12:50:57,539 - modelscope - INFO - PyTorch version 2.2.1 Found.\n",
      "2024-04-05 12:50:57,541 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-04-05 12:50:57,574 - modelscope - INFO - Loading done! Current index file version is 1.13.1, with md5 b5a2c5fe01f7460b3e700a8ce7e6fc94 and a total number of 972 components indexed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import bitsandbytes\n",
    "import accelerate\n",
    "from datasets import Dataset\n",
    "\n",
    "from modelscope import snapshot_download\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import PeftModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=r'/root/autodl-tmp/01ai/Yi-6B-Chat'\n",
    "model_dir = snapshot_download('01ai/Yi-6B-Chat', cache_dir='/root/autodl-tmp', revision='master')\n",
    "\n",
    "# base_tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True, padding_side='left', max_length=512, return_tensors='pt')\n",
    "\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "# \t model_path,\n",
    "# \t device_map='auto',\n",
    "# \t torch_dtype=torch.bfloat16,\n",
    "# \t trust_remote_code=True \n",
    "# ).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate the following words into English:\\n你係邊個？\"},\n",
    "]\n",
    "\n",
    "messages_plain = [\n",
    "    \"\"\"\n",
    "    <|im_start|> user\n",
    "    hi<|im_end|> \n",
    "    <|im_start|> assistant\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# input_ids = base_tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "# output_ids = base_model.generate(input_ids.to('cuda'))\n",
    "# # response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "# response = base_tokenizer.decode(output_ids[0], skip_special_tokens=False, max_length=100)\n",
    "\n",
    "# # Model response: \"Hello! How can I assist you today?\"\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64002\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/01ai/Yi-6B-Chat', use_fast=True, padding_side='left', max_length=512, return_tensors='pt')\n",
    "base_tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/01ai/Yi-6B-Chat', use_fast=True, padding_side='left', max_length=512, return_tensors='pt')\n",
    "print(len(tokenizer.vocab))\n",
    "# tokenizer = AutoTokenizer.from_pretrained('/root/AIST4010-Cantonese-Translator/tokenizer', use_fast=True, padding_side='left', max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PeftModel.from_pretrained(\n",
    "#     model,\n",
    "#    '/root/peft_model',\n",
    "#     is_trainable=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.56s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "\t '/root/autodl-tmp/01ai/Yi-6B-Chat',\n",
    "\t device_map=device,\n",
    "\t torch_dtype=torch.bfloat16,\n",
    "     quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    "\t trust_remote_code=True \n",
    ").eval()\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "\t model_path,\n",
    "\t device_map=device,\n",
    "\t torch_dtype=torch.bfloat16,\n",
    "\t quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    "\t trust_remote_code=True \n",
    ").eval()\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.load_adapter('/root/autodl-tmp/peft_model_sft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DIRECTORY = r'/root/'\n",
    "ABC_DICT_PATH = r'autodl-tmp/AIST4010-Cantonese-Translator-Data/ABC-Dict/abc_dict.csv'\n",
    "\n",
    "def load_abc_dataset():\n",
    "    abc_dict = pd.read_csv(REPO_DIRECTORY + ABC_DICT_PATH)\n",
    "    abc_dataset = Dataset.from_pandas(abc_dict)\n",
    "    return abc_dataset\n",
    "\n",
    "abc_set = load_abc_dataset()\n",
    "abc_shuffled_set = abc_set.train_test_split(seed=42, test_size=0.1)\n",
    "abc_train_set = abc_shuffled_set['train']\n",
    "abc_test_set = abc_shuffled_set['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'system',\n",
       "   'content': 'Translate the given English words to Cantonese.'},\n",
       "  {'role': 'user',\n",
       "   'content': \"Today my classmate wasn't careful, and kicked my left nut. It was very painful!\"}],\n",
       " [{'role': 'system',\n",
       "   'content': 'Translate the given Cantonese words to English.'},\n",
       "  {'role': 'user', 'content': '今日我同學唔小心，踢中我左面粒蛋蛋，好痛啊！'}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_messages(sample):\n",
    "    lang_map = {'English': 'en', 'Cantonese': 'yue'}\n",
    "    def get_prompt(src, tgt, sample):\n",
    "        system_prompt = f\"Translate the given {src} words to {tgt}.\"\n",
    "        user_prompt = sample[lang_map[src]]\n",
    "        return system_prompt, user_prompt\n",
    "    system1, user1 = get_prompt('English', 'Cantonese', sample)\n",
    "    system2, user2 = get_prompt('Cantonese', 'English', sample)\n",
    "    return [[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system1\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user1\n",
    "        }],\n",
    "        [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system2\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user2\n",
    "        }]\n",
    "    ]\n",
    "    \n",
    "\n",
    "train_samples = abc_train_set.shuffle(seed=10).select(range(20))\n",
    "test_samples = abc_test_set.shuffle(seed=10).select(range(20))\n",
    "\n",
    "get_messages(train_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/root/miniconda3/envs/trans/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         25585,   826,  1225, 13580,  3613, 59610, 59570, 11369,    97,   597,\n",
      "         19591,   826,  1999,  6230,    98,   983,   717,  1196, 16465,    99,\n",
      "             7, 59568,   144,     6, 14135,   144, 10721, 59646, 60588, 54274,\n",
      "           534,   453,   453, 13272,   101, 62328, 40994, 60588, 60488, 62295,\n",
      "           536,   462,   495, 62278,   101, 59706, 60544, 61459,   103,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "今日我個同學唔小心，踢到我個左邊睾丸，好痛呀！\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         10721, 59646, 54274,   534,   453,   453, 13272,   101, 62328, 59642,\n",
      "         59646, 60488, 59724, 61329, 60751, 60751,   101, 59706, 60544, 60530,\n",
      "           103,     7, 59568,   144,     6, 14135,   144, 25585,   826,  1225,\n",
      "         13580, 24870, 19591,   795,   594,   567,  1999,  1682,  1935,    97,\n",
      "           648, 26288,   810,  1272,    99,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Today my classmate accidentally kicked me in the left testicle, it hurts so much!\n",
      "\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "def model_output(model, tokenizer, messages, name=None):\n",
    "        for prompt in messages:\n",
    "                input_ids = tokenizer.apply_chat_template(conversation=prompt, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "                with torch.cuda.amp.autocast():\n",
    "                        output_ids = model.generate(input_ids.to('cuda'), max_new_tokens=100)\n",
    "                response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "                # response = tokenizer.decode(output_ids[0], skip_special_tokens=False, max_length=100)\n",
    "                print(output_ids)\n",
    "                print(f\"{name}:\\n{response}\\n\")\n",
    "\n",
    "\n",
    "print([model_output(base_model, base_tokenizer, get_messages(train_samples[0]), 'Base model'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_outputs(samples):\n",
    "    for sample in samples:\n",
    "        print(sample)\n",
    "        prompts = get_messages(sample)\n",
    "        for prompt in prompts:\n",
    "            print(f\"Prompt:\\n{prompt[0]['content']}\")\n",
    "            print()\n",
    "            model_output(base_model, base_tokenizer, [prompt], 'Base model')\n",
    "            model_output(model, tokenizer, [prompt], 'Fine-tuned model')\n",
    "\n",
    "# compare_outputs(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 25585,   826,  1225, 13580,  3613, 59610, 59570, 11369,    97,\n",
      "           597, 19591,   826,  1999,  6230,    98,   983,   717,  1196, 16465,\n",
      "            99,     7, 59568,   144,     6, 14135,   144, 10721, 59646,   534,\n",
      "           454,   483, 65228, 68360, 67373, 67644, 67373, 76988,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "今日我啲\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 10721, 59646, 54274,   534,   453,   453, 13272,   101, 62328,\n",
      "         59642, 59646, 60488, 59724, 61329, 60751, 60751,   101, 59706, 60544,\n",
      "         60530,   103,     7, 59568,   144,     6, 14135,   144, 25585,   826,\n",
      "          1225, 13580, 24870, 19591,   795,   594,   567,  1999,  1682,  1935,\n",
      "            97,  1196, 16465,    99,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Today my classmate accidentally kicked me in the left testicle, very painful!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_output(model, tokenizer, get_messages(train_samples[0]), 'Fine-tuned model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': \"Today my classmate wasn't careful, and kicked my left nut. It was very painful!\", 'yue': '今日我同學唔小心，踢中我左面粒蛋蛋，好痛啊！'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         25585,   826,  1225, 13580,  3613, 59610, 59570, 11369,    97,   597,\n",
      "         19591,   826,  1999,  6230,    98,   983,   717,  1196, 16465,    99,\n",
      "             7, 59568,   144,     6, 14135,   144, 10721, 54274, 30369,   101,\n",
      "         62328, 59642, 60488, 62295, 59599, 60751,   101, 59706, 60544, 61459,\n",
      "           103,     7]], device='cuda:0')\n",
      "Base model:\n",
      "今日同學不小心，踢中左邊的蛋，好痛呀！\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 25585,   826,  1225, 13580,  3613, 59610, 59570, 11369,    97,\n",
      "           597, 19591,   826,  1999,  6230,    98,   983,   717,  1196, 16465,\n",
      "            99,     7, 59568,   144,     6, 14135,   144, 75231, 59568, 60588,\n",
      "         65228, 70255, 67373, 59568, 60588, 67801, 68360, 59568, 74965, 59568,\n",
      "         60588, 65444,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "個 個  個\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         10721, 59646, 54274,   534,   453,   453, 13272,   101, 62328, 59642,\n",
      "         59646, 60488, 59724, 61329, 60751, 60751,   101, 59706, 60544, 60530,\n",
      "           103,     7, 59568,   144,     6, 14135,   144, 25585,   826,  1225,\n",
      "         13580, 24870, 19591,   795,   594,   567,  1999,  1682,  1935,    97,\n",
      "           648, 26288,   562,  1743,    99,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Today my classmate accidentally kicked me in the left testicle, it hurts a lot!\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 10721, 59646, 54274,   534,   453,   453, 13272,   101, 62328,\n",
      "         59642, 59646, 60488, 59724, 61329, 60751, 60751,   101, 59706, 60544,\n",
      "         60530,   103,     7, 59568,   144,     6, 14135,   144, 25585,   826,\n",
      "          1225, 13580, 24870, 19591,   795,   594,   567,  1999,  1682,  1935,\n",
      "            97,   648,  1403, 26288,    99,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Today my classmate accidentally kicked me in the left testicle, it really hurts!\n",
      "\n",
      "{'en': 'My stomach hurt so I was rolling this way and that on the bed.', 'yue': '我肚痛到捵牀捵蓆。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "          6056, 15112,  8192,   810,   616,   717, 14967,   719,  1217,   597,\n",
      "           639,   632,   567,  3807,    98,     7, 59568,   144,     6, 14135,\n",
      "           144, 59646, 61815, 60544,   101,  1953,  8943, 22085, 60760, 59670,\n",
      "         61112, 59793,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "我肚痛，所以我在床上翻来覆去。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,  6056, 15112,  8192,   810,   616,   717, 14967,   719,  1217,\n",
      "           597,   639,   632,   567,  3807,    98,     7, 59568,   144,     6,\n",
      "         14135,   144, 59646, 66481, 66789, 70255, 75400, 59568,   144, 71185,\n",
      "         75208, 75615, 68443, 68443, 68443,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "我 \n",
      "\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         59646, 61815, 60544, 59665,   535,   446,   486,   536,   442,   433,\n",
      "           535,   446,   486,   537,   452,   439,   102,     7, 59568,   144,\n",
      "             6, 14135,   144, 59597,  1064,   594,   810,  1272,  2713,   639,\n",
      "           616,   748, 59610, 59570,  1212,  8894,  1310,   632,   826,  3807,\n",
      "            98,     7]], device='cuda:0')\n",
      "Base model:\n",
      "I am in so much pain that I can't even lie down on my bed.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 59646, 61815, 60544, 59665,   535,   446,   486,   536,   442,\n",
      "           433,   535,   446,   486,   537,   452,   439,   102,     7, 59568,\n",
      "           144,     6, 14135,   144, 59597, 59610, 59583,   594,   810,  1272,\n",
      "          2713,   616,   748, 59610, 59570,  1212,  8894,  1310,   632,   567,\n",
      "          3807,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "I'm in so much pain I can't even lie down on the bed.\n",
      "\n",
      "{'en': \"I'm sorry, I can't recall right off the bat where those things of yours had got placed.\", 'yue': '唔好意思，我一時醒唔起你嗰啲嘢放咗喺邊度嘅。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         59597, 59610, 59583,  9509,    97,   616,   748, 59610, 59570,  8249,\n",
      "          1288,   965,   567, 10880,  1151,  1367,  1613,   593, 12796,   986,\n",
      "          1656,  6594,    98,     7, 59568,   144,     6, 14135,   144, 59646,\n",
      "         61641, 59721, 59635, 59937,  3326, 40401,  7752, 60080, 60588,  3583,\n",
      "           101, 59784, 19943, 60837, 61641, 59626, 60403, 61898, 59633,   102,\n",
      "             7]], device='cuda:0')\n",
      "Base model:\n",
      "我記得有把你的東西放在某個地方，但現在忘記是哪裡了。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 59597, 59610, 59583,  9509,    97,   616,   748, 59610, 59570,\n",
      "          8249,  1288,   965,   567, 10880,  1151,  1367,  1613,   593, 12796,\n",
      "           986,  1656, 64599,  1203,    98,     7, 59568,   144,     6, 14135,\n",
      "           144, 65444, 66789, 66789, 66789, 66789,   101,   534,   453,   453,\n",
      "         61641, 59721,   534,   459,   464, 66789, 66789, 66789, 66789, 66789,\n",
      "         66789, 66789, 66789, 66789, 66789,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "，唔記得嚟\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "           534,   453,   453, 59706,  7112,   101, 33442, 60531, 60808,   534,\n",
      "           453,   453, 59786, 59725,   534,   456,   481,   534,   454,   483,\n",
      "           534,   457,   467, 59932,   534,   451,   456,   534,   455,   491,\n",
      "         62295, 59781,   534,   457,   438,   102,     7, 59568,   144,     6,\n",
      "         14135,   144, 36778,    97,   616, 59610, 59583,   728,  2865, 29379,\n",
      "          2583,    98, 15842,   641,  3310,  2120,   795,  1151,   641, 59610,\n",
      "           613,  1710,  1367,  1613,   100,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Sorry, I'm not quite awake yet. Could you please tell me where you've put those things?\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,   534,   453,   453, 59706,  7112,   101, 33442, 60531, 60808,\n",
      "           534,   453,   453, 59786, 59725,   534,   456,   481,   534,   454,\n",
      "           483,   534,   457,   467, 59932,   534,   451,   456,   534,   455,\n",
      "           491, 62295, 59781,   534,   457,   438,   102,     7, 59568,   144,\n",
      "             6, 14135,   144, 36778,    97,   631,   919,  2335,   616,  2040,\n",
      "         59610, 59570,  5386,   641,   986,  1710,  1367,  1613,  8614,    98,\n",
      "             7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Sorry, for some reason I didn't notice you had put those things somewhere.\n",
      "\n",
      "{'en': 'According to what the old folks say, the winter solstice is more important than the Chinese New Year.', 'yue': '啲老人家話事偈，冬大過年。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         39559,   592,   981,   567,  1851,  8413,  1441,    97,   567,  7814,\n",
      "          1496,   608,   830,   620,   863,  1941,   989,   567,  6837,  1876,\n",
      "          8567,    98,     7, 59568,   144,     6, 14135,   144, 39559,   592,\n",
      "           981,   567,  1851,  8413,  1441,    97,   567,  7814,  1496,   608,\n",
      "           830,   620,   863,  1941,   989,   567,  6837,  1876,  8567,    98,\n",
      "             7]], device='cuda:0')\n",
      "Base model:\n",
      "According to what the old folks say, the winter solstice is more important than the Chinese New Year.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 39559,   592,   981,   567,  1851,  8413,  1441,    97,   567,\n",
      "          7814,  1496,   608,   830,   620,   863,  1941,   989,   567,  6837,\n",
      "          1876,  8567,    98,     7, 59568,   144,     6, 14135,   144, 68253,\n",
      "         59568, 72185, 67021, 67021, 77019, 67021, 76386, 59568, 72185, 74895,\n",
      "         72436, 76988, 76988,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      " \n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "           534,   454,   483, 50873, 61845, 59736,   534,   434,   441,   101,\n",
      "         60820, 59647, 60799, 59663,   102,     7, 59568,   144,     6, 14135,\n",
      "           144,  1263, 26212,  2823, 59569, 14425,  1529,   534,   454,   483,\n",
      "         50873, 61845, 59736,   534,   434,   441,   101, 60820, 59647, 60799,\n",
      "         59663, 59592, 30426,   592,  4750,   659,  1529,  2301, 59610, 59575,\n",
      "           567, 49066, 59610,  1831,   592,  3760,    97,   597,   648, 59610,\n",
      "         59575,  2143,  7814,    98, 59592,     7]], device='cuda:0')\n",
      "Base model:\n",
      "The Cantonese phrase \"啲老人家話事偈，冬大過年\" translates to English as \"It's the elders' turn to speak, and it's already winter.\"\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,   534,   454,   483, 50873, 61845, 59736,   534,   434,   441,\n",
      "           101, 60820, 59647, 60799, 59663,   102,     7, 59568,   144,     6,\n",
      "         14135,   144,  1263, 49066,  1441,   648, 59610, 59575,   567,  1288,\n",
      "          1919,   592,   771,    97,   592,  1347,   567, 29388,    98,   983,\n",
      "         59610, 59575,   567,  1288,  1919,   592,   771,   592,  9645,   567,\n",
      "         29388,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "The elders say it's the right thing to do, to follow the customs. It's the right thing to do to observe the customs.\n",
      "\n",
      "{'en': \"Tonight we've been invited to a wedding banquet.\", 'yue': '今晚有人請飲。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         59600, 51152,   666, 59610,   613,   961, 12456,   592,   562,  8760,\n",
      "          7255,  3134,    98,     7, 59568,   144,     6, 14135,   144, 33490,\n",
      "          8506, 59777, 54280, 13114, 60424, 62101,   102,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "今晚我們被邀請出席婚宴。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 59600, 51152,   666, 59610,   613,   961, 12456,   592,   562,\n",
      "          8760,  7255,  3134,    98,     7, 59568,   144,     6, 14135,   144,\n",
      "         65444, 60537, 59646,   534,   452,   444, 65379, 65444, 71507, 67801,\n",
      "         71507,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "夜我哋.\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         33490,  5189, 61919, 63105,   102,     7, 59568,   144,     6, 14135,\n",
      "           144, 59592, 33490,  5189, 61919, 63105,   102, 59592, 59568,  1229,\n",
      "         15480, 59648,  1529,  6444,   620,   663, 23025,   592,  4561, 10469,\n",
      "            98, 59592,     7]], device='cuda:0')\n",
      "Base model:\n",
      "\"今晚有人請飲。\" 可以翻译为 \"There is an invitation to drink tonight.\"\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 33490,  5189, 61919, 63105,   102,     7, 59568,   144,     6,\n",
      "         14135,   144, 14984,   824,   620,  1450,   592,  2792,   745,   592,\n",
      "          4561, 10469,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Someone is going to treat us to drink tonight.\n",
      "\n",
      "{'en': 'He has not yet been to school, or He has not studied for it yet.', 'yue': '佢未讀書。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "          4431,   815,   728,  2583,   961,   592,  1923,    97,   705,  1214,\n",
      "           815,   728,  7945,   631,   648,  2583,    98,     7, 59568,   144,\n",
      "             6, 14135,   144, 59686, 61146, 60049, 59654, 60579,   101,  2850,\n",
      "         59686, 61146, 60049, 60379, 60061, 59732, 20911,   102,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "他還未上學，或者他還未為它而學習。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,  4431,   815,   728,  2583,   961,   592,  1923,    97,   705,\n",
      "          1214,   815,   728,  7945,   631,   648,  2583,    98,     7, 59568,\n",
      "           144,     6, 14135,   144,   533,   494,   467, 65379, 74109, 72255,\n",
      "           101, 59876,   533,   494,   467, 75658, 64033, 65228,   102,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "佢，或佢。\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "           533,   494,   467, 60049, 62283, 61473,   102,     7, 59568,   144,\n",
      "             6, 14135,   144,  4431,   815,   728,  1326,  3997,    98,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "He has not read books.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,   533,   494,   467, 60049, 62283, 61473,   102,     7, 59568,\n",
      "           144,     6, 14135,   144,  4431,  8934, 59610, 59570,  5185,   592,\n",
      "          1923,  2583,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "He hasn't gone to school yet.\n",
      "\n",
      "{'en': 'Back at that time I worked as a one-star probationary police inspector, I earned twenty to thirty thousand bucks a month.', 'yue': '嗰陣時我做過一粒花嘅幫辦仔，搵兩三皮一個月。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         10298,   702,   639,   922,   616,  3983,   659,   562,   853, 59594,\n",
      "          6481, 40897,   898,  4031, 50801,    97,   616, 10989, 12445,   592,\n",
      "         19566, 12340, 25883,   562,  1780,    98,     7, 59568,   144,     6,\n",
      "         14135,   144, 61007, 59663, 59646,   534,   455,   491, 59842, 59625,\n",
      "         60273, 62007, 61044, 61748, 60298, 61343, 42994,   101, 59646, 17243,\n",
      "          5198,  7126, 59905, 14398, 61515,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "當年我喺做一星級實習警務督察，我每月收入二十至三十萬。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 10298,   702,   639,   922,   616, 72032, 17029,   659,   562,\n",
      "           853, 59594,  6481, 40897,   898,  4031, 50801,    97,   616, 10989,\n",
      "         12445,   592, 19566, 12340, 25883,   562,  1780,    98,     7, 59568,\n",
      "           144,     6, 14135,   144, 72451, 65186, 71507, 59568, 65186, 59568,\n",
      "         65186, 68981, 74171, 77749, 66757, 77019, 68443, 66757, 66757,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      " \n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "           534,   456,   481, 63598, 60531, 58409, 60799, 59625, 61329, 60048,\n",
      "           534,   457,   438, 62592, 61778, 61365,   101,   535,   449,   486,\n",
      "         61348, 59799, 60445, 12666, 59751,   102,     7, 59568,   144,     6,\n",
      "         14135,   144, 41910,   639,   922,    97,   616,   717,   562, 18063,\n",
      "          7492,  5576,    97, 20789,  1074,   592,  1604,  7883,   562,  1780,\n",
      "            98,     7]], device='cuda:0')\n",
      "Base model:\n",
      "During that time, I was a flower delivery boy, earning two to three dollars a month.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,   534,   456,   481, 63598, 60531, 58409, 60799, 59625, 61329,\n",
      "         60048,   534,   457,   438, 62592, 61778, 61365,   101,   535,   449,\n",
      "           486, 61348, 59799, 60445, 12666, 59751,   102,     7, 59568,   144,\n",
      "             6, 14135,   144,  7166,   639,   922,   616,   986,   562,  2123,\n",
      "           659,   562, 18063,  2922,    97,   878,  5134,  1074,   705,  1604,\n",
      "          7883,   562,  1780,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "At that time I had a job as a flower girl, which paid two or three dollars a month.\n",
      "\n",
      "{'en': \"Why does everyone have it, but I'm the only who doesn't?\", 'yue': '點解個個都有，得我一個冇？'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         12665,  1269,  2983,   726,   648,    97,   796,   616, 59610, 59583,\n",
      "           567,  1035,   896,  2153, 59610, 59570,   100,     7, 59568,   144,\n",
      "             6, 14135,   144, 12665,  1269,  2983,   726,   648,    97,   796,\n",
      "           616, 59610, 59583,   567,  1035,   853,   896,  2153, 59610, 59570,\n",
      "           100,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Why does everyone have it, but I'm the only one who doesn't?\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 12665,  1269,  2983,   726,   648,    97,   796,   616, 59610,\n",
      "         59583,   567,  1035,   896,  2153, 59610, 59570,   100,     7, 59568,\n",
      "           144,     6, 14135,   144, 65444, 68253, 66789, 66789, 66789,   144,\n",
      "         65444, 76988,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "\n",
      "\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         61282, 59862, 60588, 60588,  5074,   101, 59721, 59646, 12666,   534,\n",
      "           439,   440,   104,     7, 59568,   144,     6, 14135,   144, 12665,\n",
      "           620,  2983,  2339,  2286,  1635,    97,   796,   616, 59610, 59583,\n",
      "           567,  1035,   853,   728,  2286,  2507,   100,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "Why is everyone else getting something, but I'm the only one not getting anything?\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 61282, 59862, 60588, 60588,  5074,   101, 59721, 59646, 12666,\n",
      "           534,   439,   440,   104,     7, 59568,   144,     6, 14135,   144,\n",
      "         12665,   620,  2983,  2286,   853,    97,   796,   728,   795,   100,\n",
      "             7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Why is everyone getting one, but not me?\n",
      "\n",
      "{'en': \"You don't need to be concerned about the fall in the value of the US dollar, as I still know how to deal in foreign currency and make money.\", 'yue': '你唔使擔心美元嘅貶值，我仲識套匯賺錢。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "          3961,  1182, 59610, 59570,  1049,   592,   629,  7703,   883,   567,\n",
      "          3038,   594,   567,  1830,   593,   567,  2134, 11790,    97,   659,\n",
      "           616,  1451,  1082,  1040,   592,  2527,   594,  6485, 12959,   597,\n",
      "          1150,  2166,    98,     7, 59568,   144,     6, 14135,   144, 59725,\n",
      "         20357,  9773,  5061, 28533,  6685,   101,  1728, 17779,  3152,  3529,\n",
      "         59820, 60605, 59833, 16900,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "你不必担心美元价值的下降，因为我知道如何处理外币并赚钱。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,  3961,  1182, 59610, 59570,  1049,   592,   629,  7703,   883,\n",
      "           567,  3038,   594,   567,  1830,   593,   567,  2134, 11790,    97,\n",
      "           659,   616,  1451,  1082,  1040,   592,  2527,   594,  6485, 12959,\n",
      "           597,  1150,  2166,    98,     7, 59568,   144,     6, 14135,   144,\n",
      "         65444, 62861, 75004, 76386, 71507, 67938, 76988, 67801, 67801, 76988,\n",
      "         76988,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "幣\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "         59725,   534,   453,   453, 59897, 62471, 59712,  5061,   534,   457,\n",
      "           438,   537,   483,   487, 60110,   101, 59646, 61669, 62028, 60494,\n",
      "         63664,   537,   484,   491, 62617,   102,     7, 59568,   144,     6,\n",
      "         14135,   144, 59725, 20357,  9773,  5061, 59599, 49662,   101, 59646,\n",
      "         10257, 60494, 60770, 16900,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "你不必担心美元的贬值，我还会套汇赚钱。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "         72032,  1994,   592,  4750,    98,     7, 59568,   144,     6,  2942,\n",
      "           144, 59725,   534,   453,   453, 59897, 62471, 59712,  5061,   534,\n",
      "           457,   438,   537,   483,   487, 60110,   101, 59646, 61669, 62028,\n",
      "         60494, 63664,   537,   484,   491, 62617,   102,     7, 59568,   144,\n",
      "             6, 14135,   144,  3961,  1182, 59610, 59570,  1049,   592,  6761,\n",
      "           883,   567,  1825, 52704,   593,   567, 11790,    97,   616,  1451,\n",
      "          1082,  1040,   592,  1150,  2166,  1228, 12959, 25023,    98,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "You don't need to worry about the depreciation of the dollar, I still know how to make money through currency speculation.\n",
      "\n",
      "{'en': 'The two teams of the company kicked up a ruckus and the big boss had to settle it personally.', 'yue': '公司兩組人炒大鑊，要由大老細出面擺平。'}\n",
      "Prompt:\n",
      "Translate the given English words to Cantonese.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750,  3151,   592,\n",
      "         26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "          1263,  1074,  5155,   593,   567,  2165, 19591,   828,   562,   731,\n",
      "          1836,   633,   597,   567,  1741, 10920,   986,   592, 14738,   648,\n",
      "          9363,    98,     7, 59568,   144,     6, 14135,   144,  1424, 61183,\n",
      "         11315, 61348, 61791,  6619,  2244, 63598,   538,   473,   488, 60856,\n",
      "           101, 59857,   538,   456,   439, 12011, 62061, 59689, 59676, 59724,\n",
      "         35754,   102,     7]], device='cuda:0')\n",
      "Base model:\n",
      "公司內部的兩隊引起了一陣騷動，老闆不得不親自出面解決。\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858,  4750, 72032,  1994,\n",
      "           592, 26212,  2823, 59569,    98,     7, 59568,   144,     6,  2942,\n",
      "           144,  1263,  1074,  5155,   593,   567,  2165, 19591,   828,   562,\n",
      "           731,  1836,   633,   597,   567,  1741, 10920,   986,   592, 14738,\n",
      "           648,  9363,    98,     7, 59568,   144,     6, 14135,   144,  1424,\n",
      "         61348, 61791, 70311, 70889, 66789, 66789, 67613, 66789, 70328,   101,\n",
      "         71265, 66789, 66789, 66789, 66789,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "公司兩隊，\n",
      "\n",
      "Prompt:\n",
      "Translate the given Cantonese words to English.\n",
      "\n",
      "tensor([[    6,  1328,   144,  7759, 14429,   567,  1858, 26212,  2823, 59569,\n",
      "          3151,   592,  4750,    98,     7, 59568,   144,     6,  2942,   144,\n",
      "          1424, 61348, 61728, 59634, 61241, 59647,   538,   450,   443,   101,\n",
      "         59662, 59903, 59647, 59857, 62500, 59676, 59724,   535,   452,   491,\n",
      "         59849,   102,     7, 59568,   144,     6, 14135,   144, 45904, 59610,\n",
      "         59575,  1074,  3953,   678,   594,   562,  4323,    97,   597,   648,\n",
      "          5293,   567,  1741, 10920,   592,  3201,   594,   592, 14738,   648,\n",
      "            98,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Company's two groups are in a mess, and it requires the big boss to step in to settle it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_outputs(train_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'Miss Linda.', 'yue': 'Linda姐。'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "Linda姐。\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 59620, 27164, 60706,   102,\n",
      "             7, 59568,   144,     6, 14135,   144, 59620, 27164, 60706,    98,\n",
      "             7]], device='cuda:0')\n",
      "Base model:\n",
      "Linda姐.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 59620, 27164, 60706,   102,\n",
      "             7, 59568,   144,     6, 14135,   144, 59620, 27164, 60706,   101,\n",
      "         62376, 59967, 12666, 60521, 30916, 59568,   534,   457,   438, 11940,\n",
      "           102,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Linda姐，係指一個叫 Linda 嘅女士。\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "Miss Linda.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144, 30874, 30916,    98,     7,\n",
      "         59568,   144,     6, 14135,   144, 30874, 30916,    98,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "Miss Linda.\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144, 30874, 30916,    98,     7,\n",
      "         59568,   144,     6, 14135,   144, 30874, 30916, 59568, 62376, 14877,\n",
      "           101,  7112, 62376, 60352, 60181,   537,   490,   469, 60353,   102,\n",
      "         59568, 61280, 14877, 60760, 59687, 62098, 61518, 61845,   101, 59568,\n",
      "          1229, 62376, 60352, 60181,   537,   490,   469, 60353,   101, 59568,\n",
      "         59784, 62376, 60352, 60181,   537,   490,   469, 60353,   534,   457,\n",
      "           438, 62098, 61518, 61845, 60521, 60352, 60036, 62911, 60353,   102,\n",
      "         59568,  1953,   101, 59568, 60352, 30874, 30916, 60353, 59568,  1229,\n",
      "         60760, 59842, 60352, 60036, 62911,   534,   457,   438, 60251, 22799,\n",
      "         60353,   102,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Miss Linda 係英文，意思係「失蹤」。 從英文翻成廣東話， 可以係「失蹤」， 但係「失蹤」嘅廣東話叫「走佬」。 所以， 「Miss Linda」 可以翻做「走佬嘅李小姐」。\n",
      "\n",
      "{'en': 'What is he doing in the kitchen to make such banging and clanging noise?', 'yue': '佢喺廚房度打得咁𠽤叻𡃈嘞做乜嘢啊？'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "佢喺廚房度打得咁𠽤叻𡃈嘞做乜嘢啊？\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144,   533,   494,   467,   534,\n",
      "           455,   491,   534,   492,   459, 60044, 59781, 45679,   534,   451,\n",
      "           434,   545,   465,   494,   469,   534,   448,   492,   545,   466,\n",
      "           436,   441,   534,   457,   463, 59842,   533,   490,   461,   534,\n",
      "           457,   467, 60530,   104,     7, 59568,   144,     6, 14135,   144,\n",
      "          4431,   620,   594,   567,  7421,  2249,  1253,   562,  1226,  2123,\n",
      "            99,  2371,   678,   641,  2249,   100,     7]], device='cuda:0')\n",
      "Base model:\n",
      "He is in the kitchen doing such a good job! What are you doing?\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144,   533,   494,   467,   534,\n",
      "           455,   491,   534,   492,   459, 60044, 59781, 45679,   534,   451,\n",
      "           434,   545,   465,   494,   469,   534,   448,   492,   545,   466,\n",
      "           436,   441,   534,   457,   463, 59842,   533,   490,   461,   534,\n",
      "           457,   467, 60530,   104,     7, 59568,   144,     6, 14135,   144,\n",
      "          4431, 59610, 59575,   594,   567,  7421,  2249,  1253,   562,  1226,\n",
      "          2123,   639,   616,  1182, 59610, 59570,  1082,   981,   660, 59610,\n",
      "         59575,  2249,    98,     7]], device='cuda:0')\n",
      "Fine-tuned model:\n",
      "He's in the kitchen doing such a good job that I don't know what he's doing.\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "What is he doing in the kitchen to make such banging and clanging noise?\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144,  5697,   620,   660,  2249,\n",
      "           594,   567,  7421,   592,  1150,  1253,   582,  5940,   597,   845,\n",
      "          5940,  5730,   100,     7, 59568,   144,     6, 14135,   144, 10034,\n",
      "           534,   492,   459, 60044, 61898, 59842, 17103, 60418, 60732, 59676,\n",
      "         37494, 59647, 62203, 59599, 61971, 59911, 59652, 22584, 62203, 60275,\n",
      "           104,     7]], device='cuda:0')\n",
      "Base model:\n",
      "他在廚房裡做什麼會發出那麼大聲的敲打和碰撞聲音？\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144,  5697,   620,   660,  2249,\n",
      "           594,   567,  7421,   592,  1150,  1253,   582,  5940,   597,   845,\n",
      "          5940,  5730,   100,     7, 59568,   144,     6, 14135,   144,   533,\n",
      "           494,   467, 59842,   534,   451,   474,   534,   455,   491,   534,\n",
      "           492,   459, 60044,   534,   457,   438, 59781,   534,   451,   434,\n",
      "         59647, 62203,   534,   457,   438, 61385, 61385, 62203,   104,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "佢做咩喺廚房嘅度咁大聲嘅撞撞聲？\n",
      "\n",
      "{'en': 'How high do you think the possibility of success for this matter will be?', 'yue': '計你話呢件事嘅成數會有幾高呢？'}\n",
      "Prompt:\n",
      "Translate the following words from Cantonese to English:\n",
      "計你話呢件事嘅成數會有幾高呢？\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 61392, 59725, 61845, 60329,\n",
      "          9605,   534,   457,   438, 59687, 61344, 53053, 62037, 59719, 60329,\n",
      "           104,     7, 59568,   144,     6, 14135,   144,  7759,  4541,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144, 59592,  6546,  1374,\n",
      "           771,   641,  1200,   567,  2918,   631,   719,  2566,   787,   629,\n",
      "           100, 59592,     7]], device='cuda:0')\n",
      "Base model:\n",
      "Translation from Cantonese to English:\n",
      "\"How high do you think the total for this matter will be?\"\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742, 26212,\n",
      "          2823, 59569,   592,  4750, 59601,   144, 61392, 59725, 61845, 60329,\n",
      "          9605,   534,   457,   438, 59687, 61344, 53053, 62037, 59719, 60329,\n",
      "           104,     7, 59568,   144,     6, 14135,   144,  7759,  4541,   742,\n",
      "         26212,  2823, 59569,   592,  4750, 59601,   144,  9888,   641,  1200,\n",
      "           567, 16685,   631,   719,  2291,   678,  1374,   100,     7]],\n",
      "       device='cuda:0')\n",
      "Fine-tuned model:\n",
      "Translation from Cantonese to English:\n",
      "Do you think the odds for this event are high?\n",
      "\n",
      "Prompt:\n",
      "Translate the following words from English to Cantonese:\n",
      "How high do you think the possibility of success for this matter will be?\n",
      "\n",
      "tensor([[    6,  2942,   144,  7759, 14429,   567,  1926,  3151,   742,  4750,\n",
      "           592, 26212,  2823, 59569, 59601,   144,  6546,  1374,   771,   641,\n",
      "          1200,   567,  7975,   593,  2416,   631,   719,  2566,   787,   629,\n",
      "           100,     7, 59568,   144,     6, 14135,   144, 59632, 60565, 43770,\n",
      "         59654,   101, 59725, 18874, 18411, 16345, 11406, 59719,   104,     7]],\n",
      "       device='cuda:0')\n",
      "Base model:\n",
      "在這件事情上，你認為成功的可能性有多高？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_outputs(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_translate_prompt() missing 1 required positional argument: 'source_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m train_sample \u001b[38;5;241m=\u001b[39m abc_train_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      7\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m abc_test_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m en_train_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCantonese\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     10\u001b[0m en_test_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCantonese\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m test_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     11\u001b[0m yue_train_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myue\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m train_sample \u001b[38;5;241m=\u001b[39m abc_train_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      7\u001b[0m test_sample \u001b[38;5;241m=\u001b[39m abc_test_set\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m en_train_messages \u001b[38;5;241m=\u001b[39m {\u001b[43mget_translate_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCantonese\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     10\u001b[0m en_test_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCantonese\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m test_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     11\u001b[0m yue_train_messages \u001b[38;5;241m=\u001b[39m {get_translate_prompt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnglish\u001b[39m\u001b[38;5;124m'\u001b[39m, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m train_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myue\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "\u001b[0;31mTypeError\u001b[0m: get_translate_prompt() missing 1 required positional argument: 'source_text'"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Translate the following words into English:\\n乜嘢都係波士決定嘅，打工仔啲人淨係得個知字。\\n\"},\n",
    "]\n",
    "\n",
    "# get 5 random samples from train and test dataset\n",
    "train_sample = abc_train_set.shuffle(seed=42).select(range(5))\n",
    "test_sample = abc_test_set.shuffle(seed=42).select(range(5))\n",
    "\n",
    "en_train_messages = {get_translate_prompt('Cantonese', sentence) for sentence in train_sample['en']}\n",
    "en_test_messages = {get_translate_prompt('Cantonese', sentence) for sentence in test_sample['en']}\n",
    "yue_train_messages = {get_translate_prompt('English', sentence) for sentence in train_sample['yue']}\n",
    "yue_test_messages = {get_translate_prompt('English', sentence) for sentence in test_sample['yue']}\n",
    "\n",
    "for messages in [en_train_messages, en_test_messages, yue_train_messages, yue_test_messages]:\n",
    "    for message in messages:\n",
    "        print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedError",
     "evalue": "'str object' has no attribute 'role'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_generation_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1745\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[0;34m(self, conversation, chat_template, add_generation_prompt, tokenize, padding, truncation, max_length, return_tensors, return_dict, **tokenizer_kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# Compilation function uses a cache to avoid recompiling the same template\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m compiled_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_jinja_template(chat_template)\n\u001b[0;32m-> 1745\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[43mcompiled_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_generation_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_generation_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecial_tokens_map\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1750\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# There's only one sequence here, so \"longest\" makes no sense\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/jinja2/environment.py:1301\u001b[0m, in \u001b[0;36mTemplate.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_render_func(ctx))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/trans/lib/python3.10/site-packages/jinja2/environment.py:936\u001b[0m, in \u001b[0;36mEnvironment.handle_exception\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Exception handling helper.  This is used internally to either raise\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03mrewritten exceptions or return a rendered traceback for the template.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rewrite_traceback_stack\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m rewrite_traceback_stack(source\u001b[38;5;241m=\u001b[39msource)\n",
      "File \u001b[0;32m<template>:2\u001b[0m, in \u001b[0;36mtop-level template code\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUndefinedError\u001b[0m: 'str object' has no attribute 'role'"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "output_ids = model.generate(input_ids.to('cuda'))\n",
    "# response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "\n",
    "# Model response: \"Hello! How can I assist you today?\"\n",
    "print(\"Tuned model:\", response)\n",
    "\n",
    "input_ids = base_tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')\n",
    "output_ids = base_model.generate(input_ids.to('cuda'))\n",
    "# response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "response = base_tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True, max_length=100)\n",
    "\n",
    "print(\"Base model:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
